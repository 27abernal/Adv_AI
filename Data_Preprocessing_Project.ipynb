{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/27abernal/Adv_AI/blob/main/Data_Preprocessing_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSWNznStwy_W"
      },
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# Clean → Encode → Classify (KNN) - Simplified\n",
        "# ===============================================\n",
        "# Dataset: Kaggle \"Mushroom Classification\"\n",
        "# Expected file: ./mushrooms.csv\n",
        "# Team Members: Alicia & Anya\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.impute import SimpleImputer  # used ONCE as an example\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
        "    roc_curve, auc\n",
        ")\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 0) Load data\n",
        "# -----------------------------\n",
        "csv_path = \"/content/mushrooms.csv\"   # TODO: place the file or change path\n",
        "if not os.path.exists(csv_path):\n",
        "    raise FileNotFoundError(f\"Could not find {csv_path} — download from Kaggle and try again.\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Initial shape:\", df.shape)\n",
        "# TODO: Get the top 5 rows (1 line of code)\n",
        "print(df.head())  # Gets the top 5 rows of the dataframe"
      ],
      "metadata": {
        "id": "q-nEfMqWzQVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5403c115-34ab-4731-cf36-fabbcc2ea9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial shape: (8124, 23)\n",
            "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
            "0     p         x           s         n       t    p               f   \n",
            "1     e         x           s         y       t    a               f   \n",
            "2     e         b           s         w       t    l               f   \n",
            "3     p         x           y         w       t    p               f   \n",
            "4     e         x           s         g       f    n               f   \n",
            "\n",
            "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
            "0            c         n          k  ...                        s   \n",
            "1            c         b          k  ...                        s   \n",
            "2            c         b          n  ...                        s   \n",
            "3            c         n          n  ...                        s   \n",
            "4            w         b          k  ...                        s   \n",
            "\n",
            "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
            "0                      w                      w         p          w   \n",
            "1                      w                      w         p          w   \n",
            "2                      w                      w         p          w   \n",
            "3                      w                      w         p          w   \n",
            "4                      w                      w         p          w   \n",
            "\n",
            "  ring-number ring-type spore-print-color population habitat  \n",
            "0           o         p                 k          s       u  \n",
            "1           o         p                 n          n       g  \n",
            "2           o         p                 n          n       m  \n",
            "3           o         p                 k          s       u  \n",
            "4           o         e                 n          a       g  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 1) Basic cleaning (duplicates, empty rows)\n",
        "# -----------------------------\n",
        "before = df.shape[0]\n",
        "\n",
        "# TODO: Remove duplicates (1 line of code)\n",
        "df.drop_duplicates(inplace=True)  # Remove duplicate rows from the dataset\n",
        "\n",
        "print(\"Removed duplicates:\", before - df.shape[0])\n",
        "\n",
        "before = df.shape[0]\n",
        "# TODO: Drop fully empty rows (1 line of code)\n",
        "df.dropna(how='all', inplace=True)  # Remove rows where ALL values are missing\n",
        "\n",
        "print(\"Dropped fully empty rows:\", before - df.shape[0])\n",
        "\n",
        "print(\"\\nMissing values per column (top 10):\")\n",
        "# TODO: Display the missing values per column (1 line of code)\n",
        "print(df.isna().sum().head(10))  # Display top 10 columns with missing values"
      ],
      "metadata": {
        "id": "ENm8JthczZ0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989556e0-012d-4e5e-d419-2fb46aee8db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed duplicates: 0\n",
            "Dropped fully empty rows: 0\n",
            "\n",
            "Missing values per column (top 10):\n",
            "class              0\n",
            "cap-shape          0\n",
            "cap-surface        0\n",
            "cap-color          0\n",
            "bruises            0\n",
            "odor               0\n",
            "gill-attachment    0\n",
            "gill-spacing       0\n",
            "gill-size          0\n",
            "gill-color         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 2) Target & split\n",
        "# -----------------------------\n",
        "TARGET_COL = \"class\"  # TODO: change if your label column differs\n",
        "if TARGET_COL not in df.columns:\n",
        "    raise ValueError(\"Update TARGET_COL to match your dataset's label column.\")\n",
        "\n",
        "# TODO: Drop the target column from the \"X\" (1 line of code)\n",
        "X = df.drop(columns=[TARGET_COL])  # Create feature matrix by removing target column\n",
        "\n",
        "# TODO: Set up the target column (1 line of code)\n",
        "y = df[TARGET_COL]  # Create target vector containing only the class labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "print(\"\\nTrain/Test shapes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# Detect types BEFORE imputation/encoding\n",
        "# TODO: Extract the numeric columns from the training data set and store it as a list\n",
        "orig_numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
        "# TODO: Extract the categorical columns from the training data set and store it as a list\n",
        "orig_categorical_cols = X.select_dtypes(exclude=['number']).columns.tolist()\n",
        "print(\"Original numeric cols:\", orig_numeric_cols if orig_numeric_cols else \"None\")\n",
        "print(\"Original categorical cols (sample):\", orig_categorical_cols[:10])"
      ],
      "metadata": {
        "id": "S4KHsmLuzd8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ac19ab-a6a9-41b5-ddbf-896858489cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train/Test shapes: (6499, 22) (1625, 22)\n",
            "Original numeric cols: None\n",
            "Original categorical cols (sample): ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# 3) IMPUTATION (MANUAL) + one sklearn example\n",
        "# --------------------------------------------\n",
        "# Manual imputation rules:\n",
        "#  - Numeric: fill with TRAIN median\n",
        "#  - Categorical: fill with TRAIN mode\n",
        "# NOTE: We compute imputation values on TRAIN only, then apply to both TRAIN & TEST.\n",
        "\n",
        "X_train_imp = X_train.copy()\n",
        "X_test_imp  = X_test.copy()\n",
        "\n",
        "# a) Numeric → manual median\n",
        "# TODO: For each of the columns, fill the empty values with the median of the column (4 lines of code)\n",
        "# TODO: Do this for the training and test data separately.\n",
        "for col in X_train_imp.select_dtypes(include=['number']).columns:  # Loop through numeric columns\n",
        "    X_train_imp[col] = X_train_imp[col].fillna(X_train_imp[col].median())  # Fill missing values with column median in training data\n",
        "    X_test_imp[col] = X_test_imp[col].fillna(X_train_imp[col].median())  # Fill missing values with TRAIN median in test data\n",
        "\n",
        "# b) Categorical → manual mode\n",
        "# TODO: For each of the columns, fill the empty values with the mode of the column (4-5 lines of code)\n",
        "# TODO: Do this for the training and test data separately.\n",
        "for col in X_train_imp.select_dtypes(exclude=['number']).columns:  # Loop through categorical columns\n",
        "    X_train_imp[col] = X_train_imp[col].fillna(X_train_imp[col].mode()[0])  # Fill missing values with most frequent value in training data\n",
        "    X_test_imp[col] = X_test_imp[col].fillna(X_train_imp[col].mode()[0])  # Fill missing values with TRAIN mode in test data\n",
        "\n",
        "# c) One EXAMPLE using sklearn SimpleImputer on a SINGLE column (categorical)\n",
        "# Choose a categorical column present in your dataset:\n",
        "IMPUTE_EXAMPLE_COL = \"odor\"  # TODO: change if needed\n",
        "if IMPUTE_EXAMPLE_COL in X_train_imp.columns:\n",
        "    cat_imp = SimpleImputer(strategy=\"most_frequent\")\n",
        "    # Ensure the input is 2D by selecting the column as a DataFrame (not a Series)\n",
        "    X_train_imp[IMPUTE_EXAMPLE_COL] = cat_imp.fit_transform(X_train_imp[[IMPUTE_EXAMPLE_COL]]).ravel()\n",
        "    X_test_imp[IMPUTE_EXAMPLE_COL] = cat_imp.transform(X_test_imp[[IMPUTE_EXAMPLE_COL]]).ravel()\n",
        "    print(f\"\\nUsed sklearn SimpleImputer on column: {IMPUTE_EXAMPLE_COL}\")\n",
        "else:\n",
        "    print(f\"\\n[Note] Example imputer column '{IMPUTE_EXAMPLE_COL}' not found. Skipping sklearn example.\")"
      ],
      "metadata": {
        "id": "Ep4fZOdpzd6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69450efe-8be6-4749-ee6b-70111d71cd12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Used sklearn SimpleImputer on column: odor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# 4) ENCODING\n",
        "#    - EXPLICIT One-Hot Encoding on ONE chosen column\n",
        "#    - Then get_dummies for the remaining categoricals\n",
        "# --------------------------------------------\n",
        "# Choose the column for explicit OHE:\n",
        "EXPLICIT_OHE_COL = \"odor\"  # TODO: change if needed\n",
        "\n",
        "X_train_enc = X_train_imp.copy()\n",
        "X_test_enc  = X_test_imp.copy()\n",
        "\n",
        "if EXPLICIT_OHE_COL in X_train_enc.columns:\n",
        "    # EXPLICIT OHE on this ONE column — fit on TRAIN only and TEST only separately (2 lines of code)\n",
        "    # Align test columns to train (avoid unseen-category issues)\n",
        "    train_ohe = pd.get_dummies(X_train_enc[EXPLICIT_OHE_COL], prefix=EXPLICIT_OHE_COL)  # Convert categorical column to dummy variables for training data\n",
        "    test_ohe = pd.get_dummies(X_test_enc[EXPLICIT_OHE_COL], prefix=EXPLICIT_OHE_COL)  # Convert categorical column to dummy variables for test data\n",
        "    test_ohe = test_ohe.reindex(columns=train_ohe.columns, fill_value=0)  # Ensure test has same columns as train, filling missing with 0\n",
        "\n",
        "    # Drop original column and concat OHE columns\n",
        "    X_train_enc = pd.concat([X_train_enc.drop(columns=[EXPLICIT_OHE_COL]), train_ohe], axis=1)  # Remove original column and add dummy columns for training\n",
        "    X_test_enc  = pd.concat([X_test_enc.drop(columns=[EXPLICIT_OHE_COL]),  test_ohe], axis=1)  # Remove original column and add dummy columns for test\n",
        "\n",
        "    print(f\"\\nExplicit OHE applied to column: {EXPLICIT_OHE_COL}\")\n",
        "else:\n",
        "    print(f\"\\n[Note] Explicit OHE column '{EXPLICIT_OHE_COL}' not found. Skipping explicit OHE step.\")\n",
        "\n",
        "# TODO: Identify remaining categorical columns (post explicit OHE drop) in the TRAINING data set only (1 line of code)\n",
        "remaining_categorical_cols = X_train_enc.select_dtypes(include=['object']).columns.tolist()  # Find all remaining categorical columns after explicit OHE\n",
        "\n",
        "# TODO: Apply get_dummies to the remaining categoricals (fit on TRAIN, align TEST) (1 lines of code)\n",
        "X_train_enc = pd.get_dummies(X_train_enc, columns=remaining_categorical_cols)  # Automatically convert all remaining categorical columns to dummy variables\n",
        "\n",
        "# Align test columns to train columns (VERY IMPORTANT)\n",
        "X_test_enc = X_test_enc.reindex(columns=X_train_enc.columns, fill_value=0)\n",
        "\n",
        "print(\"Encoded train shape:\", X_train_enc.shape)\n",
        "print(\"Encoded test shape:\", X_test_enc.shape)"
      ],
      "metadata": {
        "id": "YNP3FuTLzoK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57afcdc8-e9cb-423d-9cae-cdcb5604c8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Explicit OHE applied to column: odor\n",
            "Encoded train shape: (6499, 117)\n",
            "Encoded test shape: (1625, 117)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# 5) NORMALIZE numeric columns (if any)\n",
        "#    (Scale ONLY the original numeric columns; don't scale one-hot columns)\n",
        "# --------------------------------------------\n",
        "# TODO: Use the Standard Scaler to scale the numeric values (1 line of code)\n",
        "scaler = StandardScaler()  # Create StandardScaler instance to standardize features (mean=0, std=1)\n",
        "\n",
        "numeric_cols_to_scale = [c for c in orig_numeric_cols if c in X_train_enc.columns]\n",
        "\n",
        "# TODO: Fit the scaler and scale the train and test data separately. (3 lines of code)\n",
        "# TODO: Print the names of the columns scaled if any (4 lines of code at max)\n",
        "if numeric_cols_to_scale:\n",
        "    X_train_enc[numeric_cols_to_scale] = scaler.fit_transform(X_train_enc[numeric_cols_to_scale])  # Fit scaler on training data and transform training numeric columns\n",
        "    X_test_enc[numeric_cols_to_scale] = scaler.transform(X_test_enc[numeric_cols_to_scale])  # Transform test numeric columns using scaler fitted on training data\n",
        "    print(f\"\\nScaled numeric columns: {numeric_cols_to_scale}\")  # Print which columns were scaled\n",
        "else:\n",
        "    print(\"No original numeric columns to scale.\")  # Inform user if no numeric columns were found to scale"
      ],
      "metadata": {
        "id": "eU9rSh2EzoIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e31db64-da4f-4894-b4ee-49cd951fdaaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No original numeric columns to scale.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# 6) KNN + Grid Search\n",
        "# --------------------------------------------\n",
        "# TODO: Use the KNN Classifier to classify the data\n",
        "knn = KNeighborsClassifier()  # Create KNN classifier instance for grid search\n",
        "# TODO: Test for number of neighbors in the set [3, 5, 7, 9, 11, 15, 21]\n",
        "# TODO: Try both the types of weights\n",
        "# TODO: Also try Manhattan and Euclidean distances.\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11, 15, 21],  # Test different k values (number of neighbors)\n",
        "    'weights': ['uniform', 'distance'],  # Test both uniform and distance-based weighting\n",
        "    'p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
        "}\n",
        "# Find and print the best_estimator_ and print the best parameters\n",
        "# Roughly 7 - 9 lines of code including printing the estimator.\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', n_jobs=-1)  # Create grid search with 5-fold cross-validation\n",
        "grid_search.fit(X_train_enc, y_train)  # Perform grid search on training data\n",
        "print(f\"\\nBest CV accuracy: {grid_search.best_score_:.4f}\")  # Print best cross-validation accuracy\n",
        "print(f\"Best params: {grid_search.best_params_}\")  # Print best hyperparameters found\n",
        "print(f\"Best estimator: {grid_search.best_estimator_}\")  # Print the best configured KNN model\n",
        "best_knn = grid_search.best_estimator_  # Store the best model for later use"
      ],
      "metadata": {
        "id": "RoDXBPSPzthN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# 7) Evaluate on held-out TEST\n",
        "# --------------------------------------------\n",
        "# TODO: Use KNN to make predictions on the test dataset (1 line of code)\n",
        "y_pred = best_knn.predict(X_test_enc)  # Generate predictions on test set using best KNN model\n",
        "\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nTest accuracy: {:.4f}\".format(test_acc))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y))\n",
        "plt.figure()\n",
        "disp.plot(values_format=\"d\")\n",
        "plt.title(\"Confusion Matrix (Test)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N1hC2iIMzuwE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}